{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12d3021d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pywhispercpp.model import Model\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "from yt_dlp import YoutubeDL\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45016206",
   "metadata": {},
   "source": [
    "### config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea9e08d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = 'data/podcast.db'\n",
    "\n",
    "input_files_dir = Path('input_files/')\n",
    "# print(input_files_dir.resolve())\n",
    "# print(list(input_files_dir.glob('*.mp3')))\n",
    "file = './s10e43_tiny_benchmark.mp3'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f119a434",
   "metadata": {},
   "source": [
    "### database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0a32e9",
   "metadata": {},
   "source": [
    "##### init database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e0c0910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a folder data/ if doesn't exist yet\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# create/connect to sqlite database\n",
    "def get_connection():\n",
    "    return sqlite3.connect(db_path)\n",
    "\n",
    "def init_db():\n",
    "    with get_connection() as db:\n",
    "        cursor = db.cursor()\n",
    "\n",
    "        # episodes table\n",
    "        cursor.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS episodes (\n",
    "                id INTEGER PRIMARY KEY,\n",
    "                title TEXT,\n",
    "                date TEXT,\n",
    "                url_path TEXT,\n",
    "                description TEXT,\n",
    "                season_number INTEGER,\n",
    "                episode_number INTEGER,\n",
    "                index_number INTEGER\n",
    "            )\n",
    "        \"\"\")\n",
    "\n",
    "        # participants table\n",
    "        cursor.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS participants (\n",
    "                id INTEGER PRIMARY KEY,\n",
    "                name TEXT NOT NULL\n",
    "            )\n",
    "        \"\"\")\n",
    "\n",
    "        # transcript segments table\n",
    "        cursor.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS transcription_segments (\n",
    "                id INTEGER PRIMARY KEY,\n",
    "                episode_id INTEGER REFERENCES episodes(id),\n",
    "                start_time REAL,\n",
    "                end_time REAL,\n",
    "                text TEXT,\n",
    "                participant_id INTEGER REFERENCES participants(id) -- speaker for diarisation\n",
    "            )\n",
    "        \"\"\")\n",
    "\n",
    "        # --- junction table for a participant in an episode\n",
    "        cursor.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS episodes_participants (\n",
    "                episode_id INTEGER REFERENCES episodes(id),\n",
    "                participant_id INTEGER REFERENCES participants(id),\n",
    "                role TEXT,\n",
    "                PRIMARY KEY (episode_id, participant_id)\n",
    "            )\n",
    "        \"\"\")\n",
    "\n",
    "        db.commit()\n",
    "\n",
    "# init the db\n",
    "init_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95283dc2",
   "metadata": {},
   "source": [
    "##### check the structure of the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d007b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "episodes\n",
      "(0, 'id', 'INTEGER', 0, None, 1)\n",
      "(1, 'title', 'TEXT', 0, None, 0)\n",
      "(2, 'date', 'TEXT', 0, None, 0)\n",
      "(3, 'url_path', 'TEXT', 0, None, 0)\n",
      "(4, 'description', 'TEXT', 0, None, 0)\n",
      "(5, 'season_number', 'INTEGER', 0, None, 0)\n",
      "(6, 'episode_number', 'INTEGER', 0, None, 0)\n",
      "(7, 'index_number', 'INTEGER', 0, None, 0)\n",
      "\n",
      "participants\n",
      "(0, 'id', 'INTEGER', 0, None, 1)\n",
      "(1, 'name', 'TEXT', 1, None, 0)\n",
      "\n",
      "transcription_segments\n",
      "(0, 'id', 'INTEGER', 0, None, 1)\n",
      "(1, 'episode_id', 'INTEGER', 0, None, 0)\n",
      "(2, 'start_time', 'REAL', 0, None, 0)\n",
      "(3, 'end_time', 'REAL', 0, None, 0)\n",
      "(4, 'text', 'TEXT', 0, None, 0)\n",
      "(5, 'participant_id', 'INTEGER', 0, None, 0)\n",
      "\n",
      "episodes_participants\n",
      "(0, 'episode_id', 'INTEGER', 0, None, 1)\n",
      "(1, 'participant_id', 'INTEGER', 0, None, 2)\n",
      "(2, 'role', 'TEXT', 0, None, 0)\n"
     ]
    }
   ],
   "source": [
    "def inspect_table_structure(table_name):\n",
    "    \"\"\"Inspect and print table structure\"\"\"\n",
    "    with get_connection() as db:\n",
    "        cursor = db.cursor()\n",
    "        cursor.execute(f'PRAGMA table_info({table_name})')\n",
    "        print(f'\\n{table_name}')\n",
    "        for col in cursor.fetchall():\n",
    "            print(col)\n",
    "\n",
    "# Usage\n",
    "tables = ['episodes', 'participants', 'transcription_segments', 'episodes_participants']\n",
    "for table in tables:\n",
    "    inspect_table_structure(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b26580",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70cefed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "whisper_init_from_file_with_params_no_state: loading model from '/Users/quentin/dev/podcast_audio_extractor/whisper.cpp/models/ggml-large-v3.bin'\n",
      "whisper_init_with_params_no_state: use gpu    = 1\n",
      "whisper_init_with_params_no_state: flash attn = 0\n",
      "whisper_init_with_params_no_state: gpu_device = 0\n",
      "whisper_init_with_params_no_state: dtw        = 0\n",
      "whisper_init_with_params_no_state: devices    = 3\n",
      "whisper_init_with_params_no_state: backends   = 3\n",
      "whisper_model_load: loading model\n",
      "whisper_model_load: n_vocab       = 51866\n",
      "whisper_model_load: n_audio_ctx   = 1500\n",
      "whisper_model_load: n_audio_state = 1280\n",
      "whisper_model_load: n_audio_head  = 20\n",
      "whisper_model_load: n_audio_layer = 32\n",
      "whisper_model_load: n_text_ctx    = 448\n",
      "whisper_model_load: n_text_state  = 1280\n",
      "whisper_model_load: n_text_head   = 20\n",
      "whisper_model_load: n_text_layer  = 32\n",
      "whisper_model_load: n_mels        = 128\n",
      "whisper_model_load: ftype         = 1\n",
      "whisper_model_load: qntvr         = 0\n",
      "whisper_model_load: type          = 5 (large v3)\n",
      "whisper_model_load: adding 1609 extra tokens\n",
      "whisper_model_load: n_langs       = 100\n",
      "whisper_default_buffer_type: using device Metal (Apple M2)\n",
      "whisper_model_load:    Metal total size =  3094.36 MB\n",
      "whisper_model_load: model size    = 3094.36 MB\n",
      "whisper_backend_init_gpu: using Metal backend\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M2\n",
      "ggml_metal_init: picking default device: Apple M2\n",
      "ggml_metal_init: using embedded metal library\n",
      "ggml_metal_init: GPU name:   Apple M2\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyApple8  (1008)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyMetal4  (5002)\n",
      "ggml_metal_init: simdgroup reduction   = true\n",
      "ggml_metal_init: simdgroup matrix mul. = true\n",
      "ggml_metal_init: has bfloat            = true\n",
      "ggml_metal_init: use bfloat            = false\n",
      "ggml_metal_init: hasUnifiedMemory      = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  = 12713.12 MB\n",
      "ggml_metal_init: skipping kernel_get_rows_bf16                     (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_1row              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_l4                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_bf16                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h128      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h256      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_f32_bf16                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_f32                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_bf16                     (not supported)\n",
      "whisper_backend_init: using BLAS backend\n",
      "whisper_init_state: kv self size  =   83.89 MB\n",
      "whisper_init_state: kv cross size =  251.66 MB\n",
      "whisper_init_state: kv pad  size  =    7.86 MB\n",
      "whisper_init_state: loading Core ML model from '/Users/quentin/dev/podcast_audio_extractor/whisper.cpp/models/ggml-large-v3-encoder.mlmodelc'\n",
      "whisper_init_state: first run on a device may take a while ...\n",
      "whisper_init_state: Core ML model loaded\n",
      "whisper_init_state: compute buffer (conv)   =   10.79 MB\n",
      "whisper_init_state: compute buffer (cross)  =   16.93 MB\n",
      "whisper_init_state: compute buffer (decode) =  100.03 MB\n"
     ]
    }
   ],
   "source": [
    "model = Model(model='large-v3', models_dir='./whisper.cpp/models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773d1a0b",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156174bc",
   "metadata": {},
   "source": [
    "##### gathering episode data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b57c8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    }
   ],
   "source": [
    "# get the season number as well as the episode number from the title string\n",
    "# the title string should be formated as such 'S01E01...'\n",
    "def extract_season_episode(episode_title:str):\n",
    "    if episode_title is None:\n",
    "        return None, None\n",
    "\n",
    "    pattern_to_find = r'S(\\d+)E(\\d+)'\n",
    "    match = re.search(pattern_to_find, episode_title)\n",
    "\n",
    "    if match:\n",
    "        season_number = int(match.group(1))\n",
    "        episode_number = int(match.group(2))\n",
    "    else:\n",
    "        season_number = None\n",
    "        episode_number = None\n",
    "\n",
    "    return season_number, episode_number\n",
    "\n",
    "# getting episode data\n",
    "def fetch_episode_data(feed_url, episode_items):\n",
    "    ydl_config = {\n",
    "        'extract_flat': False,\n",
    "        'playlist_items': episode_items,\n",
    "        'quiet': True,\n",
    "        'skip_download': True\n",
    "    }\n",
    "    with YoutubeDL(ydl_config) as ydl:\n",
    "        info = ydl.extract_info(feed_url)\n",
    "        episodes = info.get('entries', [info]) # make up a list of items from the fetched entries\n",
    "        # return info.get('entries')\n",
    "        return [\n",
    "            {\n",
    "                \"title\": episode.get(\"title\"),\n",
    "                \"description\": episode.get(\"description\"),\n",
    "                \"url\": episode.get(\"webpage_url\") or episode.get(\"original_url\"),\n",
    "                \"upload_date\": episode.get(\"upload_date\"),\n",
    "                \"playlist_index\": episode.get(\"playlist_index\"),\n",
    "                \"season_number\": season,\n",
    "                \"episode_number\": episode_num,\n",
    "            }\n",
    "            for episode in episodes\n",
    "            for season, episode_num in [extract_season_episode(episode.get('title'))]\n",
    "        ]\n",
    "\n",
    "# download episode\n",
    "def download_episode(episode_url, output_path, episode_title):\n",
    "    ydl_config = {\n",
    "        'outtmpl': f\"{output_path}/{episode_title}.%(ext)s\",\n",
    "        # 'format':'',\n",
    "        'quiet': True\n",
    "    }\n",
    "    with YoutubeDL(ydl_config) as ydl:\n",
    "        ydl.download([episode_url])\n",
    "\n",
    "# usage test\n",
    "# fetch_episode_data('https://feeds.acast.com/public/shows/floodcast', \"240\")\n",
    "test_url_episode = 'https://sphinx.acast.com/p/open/s/5ffe3facad3e633276e9ea57/e/tag%3Asoundcloud%2C2010%3Atracks%2F285183974/media.mp3#__youtubedl_smuggle=%7B%22force_videoid%22%3A+%22tag%3Asoundcloud%2C2010%3Atracks%2F285183974%22%7D'\n",
    "# download_episode(test_url_episode, './output', 'panchour')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2409c833",
   "metadata": {},
   "source": [
    "##### create episode into db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614c02af",
   "metadata": {},
   "source": [
    "##### transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0a9116",
   "metadata": {},
   "source": [
    "for testing whispercpp parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0eef854c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m\n",
      "Model.transcribe(\n",
      "    self,\n",
      "    media: Union[str, numpy.ndarray],\n",
      "    n_processors: int = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    new_segment_callback: Callable[[pywhispercpp.model.Segment], NoneType] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    **params,\n",
      ") -> List[pywhispercpp.model.Segment]\n",
      "\u001b[31mDocstring:\u001b[39m\n",
      "Transcribes the media provided as input and returns list of `Segment` objects.\n",
      "Accepts a media_file path (audio/video) or a raw numpy array.\n",
      "\n",
      ":param media: Media file path or a numpy array\n",
      ":param n_processors: if not None, it will run the transcription on multiple processes\n",
      "                     binding to whisper.cpp/whisper_full_parallel\n",
      "                     > Split the input audio in chunks and process each chunk separately using whisper_full()\n",
      ":param new_segment_callback: callback function that will be called when a new segment is generated\n",
      ":param params: keyword arguments for different whisper.cpp parameters, see ::: constants.PARAMS_SCHEMA\n",
      ":param extract_probability: If True, calculates the geometric mean of token probabilities for each segment,\n",
      "    providing a confidence score interpretable as a probability in [0, 1].\n",
      ":return: List of transcription segments\n",
      "\u001b[31mFile:\u001b[39m      ~/dev/podcast_audio_extractor/.venv/lib/python3.11/site-packages/pywhispercpp/model.py\n",
      "\u001b[31mType:\u001b[39m      function"
     ]
    }
   ],
   "source": [
    "def transcribe(file:str):\n",
    "    transcription = model.transcribe(\n",
    "        file, \n",
    "        language='fr',\n",
    "        temperature=0.0,\n",
    "        print_progress=True,\n",
    "        extract_probability=False\n",
    "    )\n",
    "    print(transcription)\n",
    "    return transcription\n",
    "\n",
    "# help(Model.transcribe)\n",
    "?Model.transcribe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed1e4c6",
   "metadata": {},
   "source": [
    "##### storing data into db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3971825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print la transcription dans un fichier\n",
    "def transcribe_into_file(file:str):\n",
    "\n",
    "    # directory to store the transcriptions into \n",
    "    output_directory = 'transcriptions_output'\n",
    "    os.makedirs(f'./{output_directory}', exist_ok=True)\n",
    "\n",
    "    # name of the transcription output file\n",
    "    # (using the name of the file given as params)\n",
    "    base_name = os.path.splitext(file)[0]\n",
    "    output_file_name = f\"{base_name}.txt\"\n",
    "\n",
    "    # writing transcriptions in file\n",
    "    with open(f'./{output_directory}/{output_file_name}','w',encoding='utf-8') as output_file:\n",
    "        for segment in transcribe(file):\n",
    "            output_file.write(f'{segment.text}')\n",
    "            # print(segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b769537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_into_db(input_files_dir):\n",
    "    \n",
    "    # for each files in the input audio files folder, it get the transcription, \n",
    "    # and then stores it in the db\n",
    "    for audio_file in input_files_dir.glob('*.mp3'):\n",
    "\n",
    "        print(f\"file being processed : {audio_file.name}\")\n",
    "        \n",
    "        # create episode and get its id\n",
    "        episode_id = create_episode_in_db(audio_file)\n",
    "\n",
    "        # store transcription segment of the episode into db\n",
    "        with get_connection() as db:\n",
    "            cursor = db.cursor()\n",
    "\n",
    "            for transcription_segment in transcribe(audio_file.name):\n",
    "                start = transcription_segment.t0\n",
    "                end = transcription_segment.t1\n",
    "                text = transcription_segment.text.strip()\n",
    "\n",
    "                cursor.execute(\"\"\"\n",
    "                    INSERT INTO transcription_segments (episode_id, start_time, end_time, text)\n",
    "                    VALUES (?,?,?,?)\n",
    "                \"\"\", (episode_num, start, end, text))\n",
    "\n",
    "            db.commit()\n",
    "\n",
    "# insert episode into db\n",
    "def create_episode_in_db(episode_data):\n",
    "    try:\n",
    "        with get_connection() as db:\n",
    "            cursor = db.cursor()\n",
    "            cursor.execute(\"\"\"\n",
    "                INSERT INTO episodes (title, date, url_path, description, season_number, episode_number, index_number)\n",
    "                VALUES (?,?,?,?,?,?,?)\n",
    "            \"\"\", (\n",
    "                episode_data.get('title'),\n",
    "                episode_data.get('upload_date'),\n",
    "                episode_data.get('url'),\n",
    "                episode_data.get('description'),\n",
    "                episode_data.get('season_number'),\n",
    "                episode_data.get('episode_number'),\n",
    "                episode_data.get('playlist_index')\n",
    "            ))\n",
    "            \n",
    "            db.commit()\n",
    "            episode_id = cursor.lastrowid\n",
    "\n",
    "        return episode_id\n",
    "    except Exception as e:\n",
    "        print(f'Error creating episode in DB: {e}')\n",
    "        return None\n",
    "\n",
    "# gather infos from API or RSS feed\n",
    "# def fetch_episode_informations(episode_num) -> tuple:\n",
    "#     return description, url_path, title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d9ea8d",
   "metadata": {},
   "source": [
    "##### main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c21aec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - get the data of the episode(s)\n",
    "# - download the audio file\n",
    "# - create the episode in the db\n",
    "def process_episodes(feed_url, episodes_items, download_path, transcription=False):\n",
    "    episodes = fetch_episode_data(feed_url, episodes_items)\n",
    "\n",
    "    for episode in episodes:\n",
    "        episode_title = episode.get('title')\n",
    "        print(episode_title)\n",
    "        \n",
    "        episode_id = create_episode_in_db(episode)\n",
    "\n",
    "        if download_path:\n",
    "            download_episode(episode['url'],download_path, episode_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01c6708",
   "metadata": {},
   "source": [
    "##### future functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5658500e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_output():\n",
    "    print('format')\n",
    "\n",
    "def vector_store():\n",
    "    print('vector')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d63361",
   "metadata": {},
   "source": [
    "##### usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2eb539",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [generic] Falling back on generic information extractor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S10E43 - Pierre Bachelet Sature\n"
     ]
    }
   ],
   "source": [
    "# transcribe_into_db(input_files_dir)\n",
    "process_episodes('https://feeds.acast.com/public/shows/floodcast','1',False, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22118a6",
   "metadata": {},
   "source": [
    "##### unload model from vram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67afd087",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# unload model from vram\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[43mmodel\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# unload model from vram (mac only)\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aab58b6",
   "metadata": {},
   "source": [
    "### embeddings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
