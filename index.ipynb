{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12d3021d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pywhispercpp.model import Model\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "from yt_dlp import YoutubeDL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45016206",
   "metadata": {},
   "source": [
    "### config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea9e08d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = 'data/podcast.db'\n",
    "\n",
    "input_files_dir = Path('input_files/')\n",
    "# print(input_files_dir.resolve())\n",
    "# print(list(input_files_dir.glob('*.mp3')))\n",
    "file = './s10e43_tiny_benchmark.mp3'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f119a434",
   "metadata": {},
   "source": [
    "### database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0a32e9",
   "metadata": {},
   "source": [
    "##### init database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e0c0910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a folder data/ if doesn't exist yet\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# create/connect to sqlite database\n",
    "def get_connection():\n",
    "    return sqlite3.connect(db_path)\n",
    "\n",
    "def init_db():\n",
    "    with get_connection() as db:\n",
    "        cursor = db.cursor()\n",
    "\n",
    "        # episodes table\n",
    "        cursor.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS episodes (\n",
    "                id INTEGER PRIMARY KEY,\n",
    "                title TEXT,\n",
    "                date TEXT,\n",
    "                url_path TEXT,\n",
    "                description TEXT,\n",
    "                season_number INTEGER,\n",
    "                episode_number INTEGER,\n",
    "                index_number INTEGER\n",
    "            )\n",
    "        \"\"\")\n",
    "\n",
    "        # participants table\n",
    "        cursor.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS participants (\n",
    "                id INTEGER PRIMARY KEY,\n",
    "                name TEXT NOT NULL\n",
    "            )\n",
    "        \"\"\")\n",
    "\n",
    "        # transcript segments table\n",
    "        cursor.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS transcription_segments (\n",
    "                id INTEGER PRIMARY KEY,\n",
    "                episode_id INTEGER REFERENCES episodes(id),\n",
    "                start_time REAL,\n",
    "                end_time REAL,\n",
    "                text TEXT,\n",
    "                participant_id INTEGER REFERENCES participants(id) -- speaker for diarisation\n",
    "            )\n",
    "        \"\"\")\n",
    "\n",
    "        # --- junction table for a participant in an episode\n",
    "        cursor.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS episodes_participants (\n",
    "                episode_id INTEGER REFERENCES episodes(id),\n",
    "                participant_id INTEGER REFERENCES participants(id),\n",
    "                role TEXT,\n",
    "                PRIMARY KEY (episode_id, participant_id)\n",
    "            )\n",
    "        \"\"\")\n",
    "\n",
    "        db.commit()\n",
    "\n",
    "# init the db\n",
    "init_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95283dc2",
   "metadata": {},
   "source": [
    "##### check the structure of the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d007b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "episodes\n",
      "(0, 'id', 'INTEGER', 0, None, 1)\n",
      "(1, 'title', 'TEXT', 0, None, 0)\n",
      "(2, 'date', 'TEXT', 0, None, 0)\n",
      "(3, 'url_path', 'TEXT', 0, None, 0)\n",
      "(4, 'description', 'TEXT', 0, None, 0)\n",
      "(5, 'season_number', 'INTEGER', 0, None, 0)\n",
      "(6, 'episode_number', 'INTEGER', 0, None, 0)\n",
      "(7, 'index_number', 'INTEGER', 0, None, 0)\n",
      "\n",
      "participants\n",
      "(0, 'id', 'INTEGER', 0, None, 1)\n",
      "(1, 'name', 'TEXT', 1, None, 0)\n",
      "\n",
      "transcription_segments\n",
      "(0, 'id', 'INTEGER', 0, None, 1)\n",
      "(1, 'episode_id', 'INTEGER', 0, None, 0)\n",
      "(2, 'start_time', 'REAL', 0, None, 0)\n",
      "(3, 'end_time', 'REAL', 0, None, 0)\n",
      "(4, 'text', 'TEXT', 0, None, 0)\n",
      "(5, 'participant_id', 'INTEGER', 0, None, 0)\n",
      "\n",
      "episodes_participants\n",
      "(0, 'episode_id', 'INTEGER', 0, None, 1)\n",
      "(1, 'participant_id', 'INTEGER', 0, None, 2)\n",
      "(2, 'role', 'TEXT', 0, None, 0)\n"
     ]
    }
   ],
   "source": [
    "def inspect_table_structure(table_name):\n",
    "    \"\"\"Inspect and print table structure\"\"\"\n",
    "    with get_connection() as db:\n",
    "        cursor = db.cursor()\n",
    "        cursor.execute(f'PRAGMA table_info({table_name})')\n",
    "        print(f'\\n{table_name}')\n",
    "        for col in cursor.fetchall():\n",
    "            print(col)\n",
    "\n",
    "# Usage\n",
    "tables = ['episodes', 'participants', 'transcription_segments', 'episodes_participants']\n",
    "for table in tables:\n",
    "    inspect_table_structure(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b26580",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70cefed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "whisper_init_from_file_with_params_no_state: loading model from '/Users/quentin/dev/podcast_audio_extractor/whisper.cpp/models/ggml-large-v3.bin'\n",
      "whisper_init_with_params_no_state: use gpu    = 1\n",
      "whisper_init_with_params_no_state: flash attn = 0\n",
      "whisper_init_with_params_no_state: gpu_device = 0\n",
      "whisper_init_with_params_no_state: dtw        = 0\n",
      "whisper_init_with_params_no_state: devices    = 3\n",
      "whisper_init_with_params_no_state: backends   = 3\n",
      "whisper_model_load: loading model\n",
      "whisper_model_load: n_vocab       = 51866\n",
      "whisper_model_load: n_audio_ctx   = 1500\n",
      "whisper_model_load: n_audio_state = 1280\n",
      "whisper_model_load: n_audio_head  = 20\n",
      "whisper_model_load: n_audio_layer = 32\n",
      "whisper_model_load: n_text_ctx    = 448\n",
      "whisper_model_load: n_text_state  = 1280\n",
      "whisper_model_load: n_text_head   = 20\n",
      "whisper_model_load: n_text_layer  = 32\n",
      "whisper_model_load: n_mels        = 128\n",
      "whisper_model_load: ftype         = 1\n",
      "whisper_model_load: qntvr         = 0\n",
      "whisper_model_load: type          = 5 (large v3)\n",
      "whisper_model_load: adding 1609 extra tokens\n",
      "whisper_model_load: n_langs       = 100\n",
      "whisper_default_buffer_type: using device Metal (Apple M2)\n",
      "whisper_model_load:    Metal total size =  3094.36 MB\n",
      "whisper_model_load: model size    = 3094.36 MB\n",
      "whisper_backend_init_gpu: using Metal backend\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M2\n",
      "ggml_metal_init: picking default device: Apple M2\n",
      "ggml_metal_init: using embedded metal library\n",
      "ggml_metal_init: GPU name:   Apple M2\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyApple8  (1008)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyMetal4  (5002)\n",
      "ggml_metal_init: simdgroup reduction   = true\n",
      "ggml_metal_init: simdgroup matrix mul. = true\n",
      "ggml_metal_init: has bfloat            = true\n",
      "ggml_metal_init: use bfloat            = false\n",
      "ggml_metal_init: hasUnifiedMemory      = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  = 12713.12 MB\n",
      "ggml_metal_init: skipping kernel_get_rows_bf16                     (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_1row              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_l4                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_bf16                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h128      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h256      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_f32_bf16                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_f32                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_bf16                     (not supported)\n",
      "whisper_backend_init: using BLAS backend\n",
      "whisper_init_state: kv self size  =   83.89 MB\n",
      "whisper_init_state: kv cross size =  251.66 MB\n",
      "whisper_init_state: kv pad  size  =    7.86 MB\n",
      "whisper_init_state: loading Core ML model from '/Users/quentin/dev/podcast_audio_extractor/whisper.cpp/models/ggml-large-v3-encoder.mlmodelc'\n",
      "whisper_init_state: first run on a device may take a while ...\n",
      "whisper_init_state: Core ML model loaded\n",
      "whisper_init_state: compute buffer (conv)   =   10.79 MB\n",
      "whisper_init_state: compute buffer (cross)  =   16.93 MB\n",
      "whisper_init_state: compute buffer (decode) =  100.03 MB\n"
     ]
    }
   ],
   "source": [
    "model = Model(model='large-v3', models_dir='./whisper.cpp/models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773d1a0b",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156174bc",
   "metadata": {},
   "source": [
    "##### gathering files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b57c8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [generic] Falling back on generic information extractor\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'tag:soundcloud,2010:tracks/285183974',\n",
       "  'title': 'S02E02 - Postiche de Fouffe',\n",
       "  'timestamp': 1475106896,\n",
       "  'direct': True,\n",
       "  'formats': [{'format_id': 'mpeg',\n",
       "    'url': 'https://stitcher2.acast.com/livestitches/6f02133700771e9698f070e0909016e3.mp3?ci=-vNnk5Kl9KDBbna5_BdvrwoxF9tpx3lRh-CYzL33gODV3gkd-ZpCZQ%3D%3D&pf=rss&sv=sphinx%401.258.0&uid=54a3fce4a605415f1bfd68bdb60be7b5&Expires=1758055111741&Key-Pair-Id=K38CTQXUSD0VVB&Signature=Ov7NsMjrMeoqIz1JB0xXTrDq3lPKmyDivwF4p1irQ8-n9o8vQBvfiyjI2GZoZTJuM4MMdjPEgJSYKu~m5KgElPszKJNc4lvUI9wF58fs~VaF77muqYAHhs~mm9xTp9l4~3OuK4WywSjf8QxmNThpnzuLcqyEdRhxNhszv66v9a5Ju15oCQIV8BRuw4i42ZFuS1W-EYMH-u3Hs8bizst40o~bgYUS8zKT0urUC560YQE5Pdo79nOvhS14pJf--Dk8KcJZoSuTcv9ipOH8FtlBmcIXlY5wysrsvQz6SPe55Q8Qb5ivIRXO~fEOvYHyQkCUHuclb~JB1pWgRBzio3wgxg__',\n",
       "    'ext': 'mp3',\n",
       "    'vcodec': 'none',\n",
       "    'protocol': 'https',\n",
       "    'audio_ext': 'mp3',\n",
       "    'video_ext': 'none',\n",
       "    'vbr': 0,\n",
       "    'abr': None,\n",
       "    'tbr': None,\n",
       "    'acodec': 'mp3',\n",
       "    'resolution': 'audio only',\n",
       "    'aspect_ratio': None,\n",
       "    'filesize_approx': None,\n",
       "    'http_headers': {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/136.0.0.0 Safari/537.36',\n",
       "     'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
       "     'Accept-Language': 'en-us,en;q=0.5',\n",
       "     'Sec-Fetch-Mode': 'navigate'},\n",
       "    'format': 'mpeg - audio only'}],\n",
       "  'subtitles': {},\n",
       "  'http_headers': {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/136.0.0.0 Safari/537.36',\n",
       "   'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
       "   'Accept-Language': 'en-us,en;q=0.5',\n",
       "   'Sec-Fetch-Mode': 'navigate'},\n",
       "  'hls_aes': None,\n",
       "  'original_url': 'https://sphinx.acast.com/p/open/s/5ffe3facad3e633276e9ea57/e/tag%3Asoundcloud%2C2010%3Atracks%2F285183974/media.mp3#__youtubedl_smuggle=%7B%22force_videoid%22%3A+%22tag%3Asoundcloud%2C2010%3Atracks%2F285183974%22%7D',\n",
       "  'webpage_url': 'https://sphinx.acast.com/p/open/s/5ffe3facad3e633276e9ea57/e/tag%3Asoundcloud%2C2010%3Atracks%2F285183974/media.mp3#__youtubedl_smuggle=%7B%22force_videoid%22%3A+%22tag%3Asoundcloud%2C2010%3Atracks%2F285183974%22%7D',\n",
       "  'webpage_url_basename': 'media.mp3',\n",
       "  'webpage_url_domain': 'sphinx.acast.com',\n",
       "  'extractor': 'generic',\n",
       "  'extractor_key': 'Generic',\n",
       "  'description': '<p>Avec Maud Givert, Sophie Riche et Sophie-Marie Larrouy.</p><br><p>Présenté par Florent Bernard et Adrien Ménielle.</p><br><p>Dans ce podcast, après le traditionnel tour de table de ce qu\\'on a kiffé récemment et une longue parenthèse sur le film \"Pattaya\", nous parlons de nos ratés estivaux, nos vacances gâchés, bref que c\\'était bien de la merde nos étés.</p><hr><p style=\\'color:grey; font-size:0.75em;\\'> Hébergé par Acast. Visitez <a style=\\'color:grey;\\' target=\\'_blank\\' rel=\\'noopener noreferrer\\' href=\\'https://acast.com/privacy\\'>acast.com/privacy</a> pour plus d\\'informations.</p>',\n",
       "  'duration': 3894.0,\n",
       "  'thumbnail': 'https://assets.pippa.io/shows/5ffe3facad3e633276e9ea57/5ffe3fb70fb4f41362812c5b.jpg',\n",
       "  'episode': 'S02E02 - Postiche de Fouffe',\n",
       "  'age_limit': 18,\n",
       "  'playlist_count': 250,\n",
       "  'playlist': 'FloodCast',\n",
       "  'playlist_id': 'https://feeds.acast.com/public/shows/floodcast',\n",
       "  'playlist_title': 'FloodCast',\n",
       "  'playlist_uploader': None,\n",
       "  'playlist_uploader_id': None,\n",
       "  'playlist_channel': None,\n",
       "  'playlist_channel_id': None,\n",
       "  'playlist_webpage_url': 'https://feeds.acast.com/public/shows/floodcast',\n",
       "  'n_entries': 1,\n",
       "  'playlist_index': 240,\n",
       "  '__last_playlist_index': 240,\n",
       "  'playlist_autonumber': 1,\n",
       "  'thumbnails': [{'url': 'https://assets.pippa.io/shows/5ffe3facad3e633276e9ea57/5ffe3fb70fb4f41362812c5b.jpg',\n",
       "    'id': '0'}],\n",
       "  'display_id': 'tag:soundcloud,2010:tracks/285183974',\n",
       "  'fulltitle': 'S02E02 - Postiche de Fouffe',\n",
       "  'duration_string': '1:04:54',\n",
       "  'upload_date': '20160928',\n",
       "  'release_year': None,\n",
       "  'requested_subtitles': None,\n",
       "  '_has_drm': None,\n",
       "  'epoch': 1758043412,\n",
       "  'requested_downloads': [{'http_headers': {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/136.0.0.0 Safari/537.36',\n",
       "     'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
       "     'Accept-Language': 'en-us,en;q=0.5',\n",
       "     'Sec-Fetch-Mode': 'navigate'},\n",
       "    'format_id': 'mpeg',\n",
       "    'url': 'https://stitcher2.acast.com/livestitches/6f02133700771e9698f070e0909016e3.mp3?ci=-vNnk5Kl9KDBbna5_BdvrwoxF9tpx3lRh-CYzL33gODV3gkd-ZpCZQ%3D%3D&pf=rss&sv=sphinx%401.258.0&uid=54a3fce4a605415f1bfd68bdb60be7b5&Expires=1758055111741&Key-Pair-Id=K38CTQXUSD0VVB&Signature=Ov7NsMjrMeoqIz1JB0xXTrDq3lPKmyDivwF4p1irQ8-n9o8vQBvfiyjI2GZoZTJuM4MMdjPEgJSYKu~m5KgElPszKJNc4lvUI9wF58fs~VaF77muqYAHhs~mm9xTp9l4~3OuK4WywSjf8QxmNThpnzuLcqyEdRhxNhszv66v9a5Ju15oCQIV8BRuw4i42ZFuS1W-EYMH-u3Hs8bizst40o~bgYUS8zKT0urUC560YQE5Pdo79nOvhS14pJf--Dk8KcJZoSuTcv9ipOH8FtlBmcIXlY5wysrsvQz6SPe55Q8Qb5ivIRXO~fEOvYHyQkCUHuclb~JB1pWgRBzio3wgxg__',\n",
       "    'ext': 'mp3',\n",
       "    'vcodec': 'none',\n",
       "    'protocol': 'https',\n",
       "    'audio_ext': 'mp3',\n",
       "    'video_ext': 'none',\n",
       "    'vbr': 0,\n",
       "    'acodec': 'mp3',\n",
       "    'resolution': 'audio only',\n",
       "    'format': 'mpeg - audio only',\n",
       "    '_filename': 'S02E02 - Postiche de Fouffe [tag：soundcloud,2010：tracks⧸285183974].mp3',\n",
       "    'filename': 'S02E02 - Postiche de Fouffe [tag：soundcloud,2010：tracks⧸285183974].mp3',\n",
       "    'filepath': '/Users/quentin/dev/podcast_audio_extractor/S02E02 - Postiche de Fouffe [tag：soundcloud,2010：tracks⧸285183974].mp3',\n",
       "    '__finaldir': '/Users/quentin/dev/podcast_audio_extractor',\n",
       "    '__files_to_move': {}}],\n",
       "  'format_id': 'mpeg',\n",
       "  'url': 'https://stitcher2.acast.com/livestitches/6f02133700771e9698f070e0909016e3.mp3?ci=-vNnk5Kl9KDBbna5_BdvrwoxF9tpx3lRh-CYzL33gODV3gkd-ZpCZQ%3D%3D&pf=rss&sv=sphinx%401.258.0&uid=54a3fce4a605415f1bfd68bdb60be7b5&Expires=1758055111741&Key-Pair-Id=K38CTQXUSD0VVB&Signature=Ov7NsMjrMeoqIz1JB0xXTrDq3lPKmyDivwF4p1irQ8-n9o8vQBvfiyjI2GZoZTJuM4MMdjPEgJSYKu~m5KgElPszKJNc4lvUI9wF58fs~VaF77muqYAHhs~mm9xTp9l4~3OuK4WywSjf8QxmNThpnzuLcqyEdRhxNhszv66v9a5Ju15oCQIV8BRuw4i42ZFuS1W-EYMH-u3Hs8bizst40o~bgYUS8zKT0urUC560YQE5Pdo79nOvhS14pJf--Dk8KcJZoSuTcv9ipOH8FtlBmcIXlY5wysrsvQz6SPe55Q8Qb5ivIRXO~fEOvYHyQkCUHuclb~JB1pWgRBzio3wgxg__',\n",
       "  'ext': 'mp3',\n",
       "  'vcodec': 'none',\n",
       "  'protocol': 'https',\n",
       "  'audio_ext': 'mp3',\n",
       "  'video_ext': 'none',\n",
       "  'vbr': 0,\n",
       "  'abr': None,\n",
       "  'tbr': None,\n",
       "  'acodec': 'mp3',\n",
       "  'resolution': 'audio only',\n",
       "  'aspect_ratio': None,\n",
       "  'filesize_approx': None,\n",
       "  'format': 'mpeg - audio only'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fetch_episode_data(feed_url, items):\n",
    "    ydl_config = {\n",
    "        'extract_flat': False,\n",
    "        'playlist_items': items,\n",
    "        'quiet': True,\n",
    "        'skip_download': True\n",
    "    }\n",
    "    with YoutubeDL(ydl_config) as ydl:\n",
    "        info = ydl.extract_info(feed_url)\n",
    "        episodes = info.get('entries', [info]) # make up a list of items from the fetched entries\n",
    "        return info.get('entries')\n",
    "        return [\n",
    "            {\n",
    "                \"title\": episode.get(\"title\"),\n",
    "                \"description\": episode.get(\"description\"),\n",
    "                \"url\": episode.get(\"webpage_url\") or episode.get(\"original_url\"),\n",
    "                \"upload_date\": episode.get(\"upload_date\"),\n",
    "                \"playlist_index\": episode.get(\"playlist_index\"),\n",
    "                \"season_number\": episode.get(\"season_number\"),\n",
    "                \"episode_number\": episode.get(\"episode_number\"),\n",
    "            }\n",
    "            for episode in episodes\n",
    "        ]\n",
    "\n",
    "# usage\n",
    "fetch_episode_data('https://feeds.acast.com/public/shows/floodcast', \"240\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614c02af",
   "metadata": {},
   "source": [
    "##### transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0a9116",
   "metadata": {},
   "source": [
    "for testing whispercpp parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0eef854c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m\n",
      "Model.transcribe(\n",
      "    self,\n",
      "    media: Union[str, numpy.ndarray],\n",
      "    n_processors: int = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    new_segment_callback: Callable[[pywhispercpp.model.Segment], NoneType] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    **params,\n",
      ") -> List[pywhispercpp.model.Segment]\n",
      "\u001b[31mDocstring:\u001b[39m\n",
      "Transcribes the media provided as input and returns list of `Segment` objects.\n",
      "Accepts a media_file path (audio/video) or a raw numpy array.\n",
      "\n",
      ":param media: Media file path or a numpy array\n",
      ":param n_processors: if not None, it will run the transcription on multiple processes\n",
      "                     binding to whisper.cpp/whisper_full_parallel\n",
      "                     > Split the input audio in chunks and process each chunk separately using whisper_full()\n",
      ":param new_segment_callback: callback function that will be called when a new segment is generated\n",
      ":param params: keyword arguments for different whisper.cpp parameters, see ::: constants.PARAMS_SCHEMA\n",
      ":param extract_probability: If True, calculates the geometric mean of token probabilities for each segment,\n",
      "    providing a confidence score interpretable as a probability in [0, 1].\n",
      ":return: List of transcription segments\n",
      "\u001b[31mFile:\u001b[39m      ~/dev/podcast_audio_extractor/.venv/lib/python3.11/site-packages/pywhispercpp/model.py\n",
      "\u001b[31mType:\u001b[39m      function"
     ]
    }
   ],
   "source": [
    "def transcribe(file:str):\n",
    "    transcription = model.transcribe(\n",
    "        file, \n",
    "        language='fr',\n",
    "        temperature=0.0,\n",
    "        print_progress=True,\n",
    "        extract_probability=False\n",
    "    )\n",
    "    print(transcription)\n",
    "    return transcription\n",
    "\n",
    "# help(Model.transcribe)\n",
    "?Model.transcribe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed1e4c6",
   "metadata": {},
   "source": [
    "##### storing data into db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3971825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print la transcription dans un fichier\n",
    "def transcribe_into_file(file:str):\n",
    "\n",
    "    # directory to store the transcriptions into \n",
    "    output_directory = 'transcriptions_output'\n",
    "    os.makedirs(f'./{output_directory}', exist_ok=True)\n",
    "\n",
    "    # name of the transcription output file\n",
    "    # (using the name of the file given as params)\n",
    "    base_name = os.path.splitext(file)[0]\n",
    "    output_file_name = f\"{base_name}.txt\"\n",
    "\n",
    "    # writing transcriptions in file\n",
    "    with open(f'./{output_directory}/{output_file_name}','w',encoding='utf-8') as output_file:\n",
    "        for segment in transcribe(file):\n",
    "            output_file.write(f'{segment.text}')\n",
    "            # print(segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b769537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_into_db(input_files_dir):\n",
    "    \n",
    "    # for each files in the input audio files folder, it get the transcription, \n",
    "    # and then stores it in the db\n",
    "    for audio_file in input_files_dir.glob('*.mp3'):\n",
    "\n",
    "        print(f\"file being processed : {audio_file.name}\")\n",
    "        \n",
    "        # create episode and get its id\n",
    "        episode_id = create_episode(audio_file)\n",
    "\n",
    "        # store transcription segment of the episode into db\n",
    "        with get_connection() as db:\n",
    "            cursor = db.cursor()\n",
    "\n",
    "            for transcription_segment in transcribe(audio_file.name):\n",
    "                start = transcription_segment.t0\n",
    "                end = transcription_segment.t1\n",
    "                text = transcription_segment.text.strip()\n",
    "\n",
    "                cursor.execute(\"\"\"\n",
    "                    INSERT INTO transcription_segments (episode_id, start_time, end_time, text)\n",
    "                    VALUES (?,?,?,?)\n",
    "                \"\"\", (episode_num, start, end, text))\n",
    "\n",
    "            db.commit()\n",
    "\n",
    "# insert episode into db\n",
    "def create_episode(episode_num):\n",
    "\n",
    "    description, url_path, title = fetch_episode_informations(episode_num)\n",
    "\n",
    "    episode_season = \n",
    "    episode_number = \n",
    "    index_number = \n",
    "\n",
    "    with get_connection() as db:\n",
    "        cursor = db.cursor()\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO episodes (title, url_path, description, )\n",
    "            VALUES (?,?,?)\n",
    "        \"\"\", (title, url_path, description))\n",
    "        \n",
    "        db.commit()\n",
    "\n",
    "    return episode_id\n",
    "\n",
    "# gather infos from API or RSS feed\n",
    "def fetch_episode_informations(episode_num) -> tuple:\n",
    "    return description, url_path, title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01c6708",
   "metadata": {},
   "source": [
    "##### future functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5658500e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_output():\n",
    "    print('format')\n",
    "\n",
    "def vector_store():\n",
    "    print('vector')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d63361",
   "metadata": {},
   "source": [
    "##### usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2eb539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file being processed : s10e43_tiny_benchmark.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:   0%\n",
      "Progress:  36%\n",
      "Progress:  78%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t0=0, t1=140, text=Message publicitaire., probability=nan, t0=140, t1=1022, text=Le médicament Daflon 500 mg, indiqué pour soulager les jambes lourdes et douloureuses dues à l'insuffisance veineuse, agit en renforçant le tonus veineux et en protégeant les vaisseaux sanguins., probability=nan, t0=1022, t1=1874, text=Son efficacité a été cliniquement démontrée dans le traitement des troubles de la circulation veineuse, jambes lourdes, douleurs, impatience, en complément des mesures hygiéno-diététiques., probability=nan, t0=1874, t1=2034, text=Rendez-vous sur Daflon.fr., probability=nan, t0=2034, t1=2624, text=Daflon 500 mg, composé de fractions flavonoïques purifiées micronisées et réservées à l'adulte, est disponible en pharmacie sans ordonnance., probability=nan, t0=2624, t1=3006, text=Tout médicament peut exposer à des risques. Parlez-en à votre pharmacien et lisez attentivement la notice., probability=nan, t0=3006, t1=3230, text=Si les symptômes persistent, consultez votre médecin., probability=nan, t0=5624, t1=6090, text=Ah non, je suis là. Vous qui n'avez pas d'invité pour nous mettre la honte de cette intro., probability=nan, t0=6090, t1=6388, text=Bonjour, bonsoir et bienvenue dans ce nouvel épisode et dernier., probability=nan, t0=6388, t1=6560, text=Ah, je le dis quand même., probability=nan, t0=6560, t1=7028, text=Parce que je me disais, est-ce qu'il va faire le truc de bienvenue dans ce dernier épisode du podcast ?, probability=nan, t0=7028, t1=7164, text=Ah non, je le fais à l'arrache quand même., probability=nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'episode_num' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# transcribe_into_file(file)\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# transcribe(file)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mtranscribe_into_db\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_files_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 39\u001b[39m, in \u001b[36mtranscribe_into_db\u001b[39m\u001b[34m(input_files_dir)\u001b[39m\n\u001b[32m     33\u001b[39m     end = transcription_segment.t1\n\u001b[32m     34\u001b[39m     text = transcription_segment.text.strip()\n\u001b[32m     36\u001b[39m     cursor.execute(\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[33m        INSERT INTO transcription_segments (episode_id, start_time, end_time, text)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[33m        VALUES (?,?,?,?)\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m \u001b[33m    \u001b[39m\u001b[33m\"\"\"\u001b[39m, (\u001b[43mepisode_num\u001b[49m, start, end, text))\n\u001b[32m     41\u001b[39m db.commit()\n",
      "\u001b[31mNameError\u001b[39m: name 'episode_num' is not defined"
     ]
    }
   ],
   "source": [
    "transcribe_into_db(input_files_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22118a6",
   "metadata": {},
   "source": [
    "##### unload model from vram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67afd087",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# unload model from vram\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[43mmodel\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# unload model from vram (mac only)\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aab58b6",
   "metadata": {},
   "source": [
    "### embeddings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
