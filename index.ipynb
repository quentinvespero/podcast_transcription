{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12d3021d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pywhispercpp.model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70cefed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "whisper_init_from_file_with_params_no_state: loading model from '/Users/quentin/dev/podcast_audio_extractor/whisper.cpp/models/ggml-large-v3.bin'\n",
      "whisper_init_with_params_no_state: use gpu    = 1\n",
      "whisper_init_with_params_no_state: flash attn = 0\n",
      "whisper_init_with_params_no_state: gpu_device = 0\n",
      "whisper_init_with_params_no_state: dtw        = 0\n",
      "whisper_init_with_params_no_state: devices    = 3\n",
      "whisper_init_with_params_no_state: backends   = 3\n",
      "whisper_model_load: loading model\n",
      "whisper_model_load: n_vocab       = 51866\n",
      "whisper_model_load: n_audio_ctx   = 1500\n",
      "whisper_model_load: n_audio_state = 1280\n",
      "whisper_model_load: n_audio_head  = 20\n",
      "whisper_model_load: n_audio_layer = 32\n",
      "whisper_model_load: n_text_ctx    = 448\n",
      "whisper_model_load: n_text_state  = 1280\n",
      "whisper_model_load: n_text_head   = 20\n",
      "whisper_model_load: n_text_layer  = 32\n",
      "whisper_model_load: n_mels        = 128\n",
      "whisper_model_load: ftype         = 1\n",
      "whisper_model_load: qntvr         = 0\n",
      "whisper_model_load: type          = 5 (large v3)\n",
      "whisper_model_load: adding 1609 extra tokens\n",
      "whisper_model_load: n_langs       = 100\n",
      "whisper_default_buffer_type: using device Metal (Apple M2)\n",
      "whisper_model_load:    Metal total size =  3094.36 MB\n",
      "whisper_model_load: model size    = 3094.36 MB\n",
      "whisper_backend_init_gpu: using Metal backend\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M2\n",
      "ggml_metal_init: picking default device: Apple M2\n",
      "ggml_metal_init: using embedded metal library\n",
      "ggml_metal_init: GPU name:   Apple M2\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyApple8  (1008)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)\n",
      "ggml_metal_init: simdgroup reduction   = true\n",
      "ggml_metal_init: simdgroup matrix mul. = true\n",
      "ggml_metal_init: has bfloat            = true\n",
      "ggml_metal_init: use bfloat            = false\n",
      "ggml_metal_init: hasUnifiedMemory      = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  = 11453.25 MB\n",
      "ggml_metal_init: skipping kernel_get_rows_bf16                     (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_1row              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_l4                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_bf16                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h128      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h256      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_f32_bf16                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_f32                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_bf16                     (not supported)\n",
      "whisper_backend_init: using BLAS backend\n",
      "whisper_init_state: kv self size  =   83.89 MB\n",
      "whisper_init_state: kv cross size =  251.66 MB\n",
      "whisper_init_state: kv pad  size  =    7.86 MB\n",
      "whisper_init_state: loading Core ML model from '/Users/quentin/dev/podcast_audio_extractor/whisper.cpp/models/ggml-large-v3-encoder.mlmodelc'\n",
      "whisper_init_state: first run on a device may take a while ...\n",
      "whisper_init_state: Core ML model loaded\n",
      "whisper_init_state: compute buffer (conv)   =   10.79 MB\n",
      "whisper_init_state: compute buffer (cross)  =   16.93 MB\n",
      "whisper_init_state: compute buffer (decode) =  100.03 MB\n"
     ]
    }
   ],
   "source": [
    "model = Model(model='large-v3', models_dir='./whisper.cpp/models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b769537",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:   0%\n",
      "Progress:  18%\n",
      "Progress:  38%\n",
      "Progress:  59%\n",
      "Progress:  80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message publicitaire.\n",
      "Le médicament Daflon 500 mg, indiqué pour soulager les jambes lourdes et douloureuses dues à l'insuffisance veineuse, agit en renforçant le tonus veineux et en protégeant les vaisseaux sanguins.\n",
      "Son efficacité a été cliniquement démontrée dans le traitement des troubles de la circulation veineuse, jambes lourdes, douleurs, impatience, en complément des mesures hygiéno-diététiques.\n",
      "Rendez-vous sur Daflon.fr.\n",
      "Daflon 500 mg, composé de fractions flavonoïques purifiées micronisées et réservées à l'adulte, est disponible en pharmacie sans ordonnance.\n",
      "Tout médicament peut exposer à des risques. Parlez-en à votre pharmacien et lisez attentivement la notice.\n",
      "Si les symptômes persistent, consultez votre médecin.\n",
      "Bonjour, je suis là. Vous qui n'avez pas d'invité pour nous mettre la honte de cette intro.\n",
      "Bonjour, bonsoir et bienvenue dans ce nouvel épisode et dernier.\n",
      "Ah, je le dis quand même.\n",
      "Parce que je me disais, est-ce qu'il va faire le truc de bienvenue dans ce dernier épisode du Floodcast ?\n",
      "Ah non, je le fais à la rage comme ça.\n",
      "Tu l'as fait, nouvel et dernier.\n",
      "Nouvel et dernier épisode du Floodcast.\n",
      "Chialé, chialé.\n",
      "On s'est dit, en gros c'est Adrien qui a eu l'idée, mais j'étais d'accord avec lui, de ne pas finir sur des lives parce qu'on sait que les lives ce n'est pas forcément les meilleurs qui ont été d'écoute, etc.\n",
      "Donc pourquoi pas faire un vrai petit au revoir.\n",
      "Voilà, un petit bilan calmement, on se remet en chagas ce temps.\n",
      "Comment vas-tu Adrien déjà ?\n",
      "Eh bien, ça va bien.\n",
      "Ça va ? Remis de tes émotions ?\n",
      "Oui.\n",
      "C'est trois grosses journées.\n",
      "D'ailleurs, je voulais dire aux gens que quand je dis que je vais être en dépression et tout, c'était une blague.\n",
      "Parce que vraiment tout le monde après m'a dit, alors déjà genre...\n",
      "Déjà, sympa de te faire, alors ? Alors tu déprimes ?\n",
      "Non, non, mais je sais qu'après le dernier live, dans la...\n",
      "À rue, il y a des gens qui sont venus demander des photos et tout.\n",
      "Et après, en partant, ils ont dit, bon et puis ça va aller, prends soin de toi et tout.\n",
      "Non, mais je ne vais pas me flinguer, c'est bon.\n",
      "Et en vrai, je ne sais pas toi, mais moi, je n'ai pas du tout eu même de tristesse, de mélancolie, rien.\n",
      "J'étais vraiment juste de la satisfaction d'avoir bien clôturé le truc.\n",
      "Comme on l'entendait.\n",
      "Avec bon entendeur même.\n",
      "Ça, on l'a coupé au montage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%\n"
     ]
    }
   ],
   "source": [
    "segments = model.transcribe('./s10e43_evenMoreTrimmed_benchmark.mp3', language='fr',)\n",
    "\n",
    "for segment in segments:\n",
    "    print(segment.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
