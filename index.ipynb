{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12d3021d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pywhispercpp.model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cefed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "whisper_init_from_file_with_params_no_state: loading model from '/home/quentin/dev/podcast_transcription/whisper.cpp/models/ggml-large-v3.bin'\n",
      "whisper_init_with_params_no_state: use gpu    = 1\n",
      "whisper_init_with_params_no_state: flash attn = 0\n",
      "whisper_init_with_params_no_state: gpu_device = 0\n",
      "whisper_init_with_params_no_state: dtw        = 0\n",
      "whisper_init_with_params_no_state: devices    = 1\n",
      "whisper_init_with_params_no_state: backends   = 1\n",
      "whisper_model_load: loading model\n",
      "whisper_model_load: n_vocab       = 51866\n",
      "whisper_model_load: n_audio_ctx   = 1500\n",
      "whisper_model_load: n_audio_state = 1280\n",
      "whisper_model_load: n_audio_head  = 20\n",
      "whisper_model_load: n_audio_layer = 32\n",
      "whisper_model_load: n_text_ctx    = 448\n",
      "whisper_model_load: n_text_state  = 1280\n",
      "whisper_model_load: n_text_head   = 20\n",
      "whisper_model_load: n_text_layer  = 32\n",
      "whisper_model_load: n_mels        = 128\n",
      "whisper_model_load: ftype         = 1\n",
      "whisper_model_load: qntvr         = 0\n",
      "whisper_model_load: type          = 5 (large v3)\n",
      "whisper_model_load: adding 1609 extra tokens\n",
      "whisper_model_load: n_langs       = 100\n",
      "whisper_model_load:      CPU total size =  3094.36 MB\n",
      "whisper_model_load: model size    = 3094.36 MB\n",
      "whisper_init_state: kv self size  =   83.89 MB\n",
      "whisper_init_state: kv cross size =  251.66 MB\n",
      "whisper_init_state: kv pad  size  =    7.86 MB\n",
      "whisper_init_state: compute buffer (conv)   =   36.13 MB\n",
      "whisper_init_state: compute buffer (encode) =  212.29 MB\n",
      "whisper_init_state: compute buffer (cross)  =    9.25 MB\n",
      "whisper_init_state: compute buffer (decode) =   99.10 MB\n",
      "Progress:   0%\n"
     ]
    }
   ],
   "source": [
    "model = Model(model='large-v3', models_dir='./whisper.cpp/models')\n",
    "# segments = model.transcribe('./s10e43_moreTrimmed_benchmark.mp3', )\n",
    "\n",
    "# for segment in segments:\n",
    "#     print(segment.text)\n",
    "\n",
    "print(model.system_info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
